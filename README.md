
## Project: Disaster Response Pipeline 

### Table of Content
  * [Motivation](#motivation)
  * [Objective](#objective) 
  * [Overview](#overview) 
 
  
  
  
### Motivation 
In this project, I'll apply data engineering skills to analyze disaster data from  [Figure Eight](https://www.figure-eight.com/)  to build a model for an API that classifies disaster messages.



### Objective 
This project is part of the [**Udacity**](https://eu.udacity.com/) **Data Scientist Nanodegree Program: Disaster Response Pipeline Project** and the goal was to apply the data engineering skills learned in the course to analyze disaster data from [Figure Eight](https://www.figure-eight.com/) to build a model for an API that classifies disaster messages. 

### Overview 
During and immediately after natural disaster there are millions of communication to disaster response organizations either direct or through social media. Disaster response organizations have to to filter and pull out the most important messages from this huge amount of communications a and redirect specific requests or indications to the proper organization that takes care of medical aid, water, logistics ecc. Every second is vital in this kind of situations, so handling the message correctly is the key. 
**The project is divided in three sections:**

1. Data Processing: 
 build an ETL (Extract, Transform, and Load) Pipeline to extract data from the given dataset, clean the data, and then store it in a **SQLite** database

2. Machine Learning Pipeline: 
split the data into a training set and a test set. Then, create a machine learning pipeline that uses NLTK, as well as scikit-learnâ€™s Pipeline and GridSearchCV to output a final model that predicts a message classifications for the 36 categories (multi-output classification)

3. Web development: develop a web application to show classify messages in real time


